{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Decorator and Factory Patterns on Creating Model Testing Methods\n",
    "\n",
    "Guanzhuo Qiao\n",
    "10/30/2019\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this articel, we try to use design patterns in Python to provide the model testing solution. As we have different methods, we can use factory to create them and we aslo need to record the scores of every methods, so we need decorator to do this job too.\n",
    "\n",
    "Here we delare some classes. The first one is the method factory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelFactory:\n",
    "    def __init__(self):\n",
    "        self.model_book = {}\n",
    "\n",
    "    def register_model(self,model_name,model_obj):\n",
    "        self.model_book[model_name] = model_obj\n",
    "\n",
    "    def get_fitter(self,model_name):\n",
    "        fitter = self.model_book.get(model_name)\n",
    "        if not fitter:\n",
    "            raise ValueError(model_name)\n",
    "        return fitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define a dataset class in order to add the functions we want into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "    def __init__(self,x_train,y_train,x_test,y_test):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.fitter = None\n",
    "\n",
    "    def fit(self,fitter,**kwargs):\n",
    "        self.fitter = fitter\n",
    "        self.fitter.set_data(self.x_train,self.y_train,self.x_test,self.y_test)\n",
    "        self.fitter.fit(**kwargs)\n",
    "\n",
    "    def get_score(self):\n",
    "        return self.fitter.get_score()\n",
    "\n",
    "    def get_confusion_matrix(self,**kwargs):\n",
    "        return self.fitter.get_confusion_matrix(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the decorator and interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record(record_dic,record_key):\n",
    "    def decorator(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            result = func(*args, **kwargs)\n",
    "            record_dic[record_key] = result\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "class ObjFitter:\n",
    "    def __init__(self):\n",
    "        self.fitter = None\n",
    "        self.fitable = None\n",
    "        self.score_book = {}\n",
    "        self.method_name = None\n",
    "\n",
    "    def fit(self,fitable, method,factory_obj,**kwargs):\n",
    "        self.method_name = method\n",
    "        self.fitter = factory_obj.get_fitter(method)\n",
    "        self.fitable = fitable\n",
    "        self.fitable.fit(self.fitter,**kwargs)\n",
    "\n",
    "    def get_score(self):\n",
    "        @record(self.score_book,self.method_name)\n",
    "        def wrapper():\n",
    "            return self.fitable.get_score()\n",
    "        wrapper()\n",
    "        return self.score_book[self.method_name]\n",
    "\n",
    "    def get_confusion_matrix(self,**kwargs):\n",
    "        return self.fitable.get_confusion_matrix(**kwargs)\n",
    "\n",
    "    def get_score_book(self):\n",
    "        return self.score_book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define the methods wrappers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fitter_Core:\n",
    "    def __init__(self):\n",
    "        self.x_train = None\n",
    "        self.y_train = None\n",
    "        self.x_test = None\n",
    "        self.y_test = None\n",
    "        self.model = None\n",
    "        self.y_pred = None\n",
    "\n",
    "    def set_data(self,x_train,y_train,x_test,y_test):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.model = None\n",
    "        self.y_pred = None\n",
    "    def fit(self):\n",
    "        pass\n",
    "    def get_score(self):\n",
    "        pass\n",
    "    def get_confusion_matrix(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DT_Fitter(Fitter_Core):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self,**kwargs):\n",
    "        self.model = tree.DecisionTreeClassifier(**kwargs)\n",
    "        self.model.fit(self.x_train,self.y_train)\n",
    "        self.y_pred = self.model.predict(self.x_test)\n",
    "\n",
    "    def get_score(self):\n",
    "        assert self.model , \"Model haven't fitted yet, please fit first\"\n",
    "        return self.model.score(self.x_test,self.y_test)\n",
    "\n",
    "    def get_confusion_matrix(self,**kwargs):\n",
    "        assert self.model, \"Model haven't fitted yet, please fit first\"\n",
    "        return confusion_matrix(self.y_test,self.y_pred,**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RF_Fitter(Fitter_Core):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self,**kwargs):\n",
    "        self.model = RandomForestClassifier(**kwargs)\n",
    "        self.model.fit(self.x_train,self.y_train)\n",
    "        self.y_pred = self.model.predict(self.x_test)\n",
    "\n",
    "    def get_score(self):\n",
    "        assert self.model , \"Model haven't fitted yet, please fit first\"\n",
    "        return self.model.score(self.x_test,self.y_test)\n",
    "\n",
    "    def get_confusion_matrix(self,**kwargs):\n",
    "        assert self.model, \"Model haven't fitted yet, please fit first\"\n",
    "        return confusion_matrix(self.y_test,self.y_pred,**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM_Fitter(Fitter_Core):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self,**kwargs):     # gamma='scale', decision_function_shape='ovo'\n",
    "        self.model = svm.SVC(**kwargs)\n",
    "        self.model.fit(self.x_train[:1000],self.y_train.ravel()[:1000])\n",
    "        self.y_pred = self.model.predict(self.x_test)\n",
    "\n",
    "    def get_score(self):\n",
    "        assert self.model , \"Model haven't fitted yet, please fit first\"\n",
    "        return self.model.score(self.x_test,self.y_test)\n",
    "\n",
    "    def get_confusion_matrix(self,**kwargs):\n",
    "        assert self.model, \"Model haven't fitted yet, please fit first\"\n",
    "        return confusion_matrix(self.y_test,self.y_pred,**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_Fitter(Fitter_Core):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.train_dataset = None\n",
    "        self.test_dataset = None\n",
    "        self.history = None\n",
    "    def set_data(self,x_train,y_train,x_test,y_test):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "        self.test_dataset  = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "        self.model = None\n",
    "        self.y_pred = None\n",
    "        self.history = None\n",
    "    def fit(self,**kwargs):\n",
    "        BATCH_SIZE = 64\n",
    "        SHUFFLE_BUFFER_SIZE = 100\n",
    "        self.train_dataset = self.train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "        self.test_dataset = self.test_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "        self.model = tf.keras.Sequential([tf.keras.layers.Dense(128, input_shape=[2]),\n",
    "                                          tf.keras.layers.Dense(128, activation='relu'),\n",
    "                                          tf.keras.layers.Dense(100, activation='softmax')])\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(),\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "            metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "        )\n",
    "        self.history = self.model.fit(\n",
    "            self.train_dataset,\n",
    "            validation_data=self.test_dataset,\n",
    "            epochs=2\n",
    "        )\n",
    "        self.y_pred = self.model.predict_classes(self.x_test)\n",
    "\n",
    "    def get_score(self):\n",
    "        assert self.model, \"Model haven't fitted yet, please fit first\"\n",
    "        return self.history.history['sparse_categorical_accuracy'][-1]\n",
    "\n",
    "    def get_confusion_matrix(self,**kwargs):\n",
    "        assert self.model, \"Model haven't fitted yet, please fit first\"\n",
    "        return confusion_matrix(self.y_test, self.y_pred, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason why we use this pattern is that we want seperate the interface and methods. By define a new method class we can easily add the methods we want and we don't need to modify other functions or classes. \n",
    "\n",
    "Finally, lets look at the results. Here we still use the dataset from FannieMae. First we process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(322866, 2)\n",
      "(322866, 1)\n",
      "(322866, 3)\n",
      "(322866, 2)\n",
      "(322866, 1)\n",
      "Train Number: 258292\n",
      "X_Train: (258292, 2)\n",
      "X_Test: (64574, 2)\n",
      "====================\n",
      "y_Train: (258292, 1)\n",
      "y_Test:  (64574, 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(r\"D:\\Grad3\\690\\FannieMae-master\\FannieMae-master\\2010Q1\")\n",
    "AcquisitionColumnNames = (\n",
    "    \"LOAN_ID\", \"ORIG_CHN\", \"Seller.Name\",\n",
    "    \"ORIG_RT\", \"ORIG_AMT\", \"ORIG_TRM\", \"ORIG_DTE\",\n",
    "    \"FRST_DTE\", \"OLTV\", \"OCLTV\", \"NUM_BO\",\n",
    "    \"DTI\", \"CSCORE_B\", \"FTHB_FLG\", \"PURPOSE\",\n",
    "    \"PROP_TYP\", \"NUM_UNIT\", \"OCC_STAT\", \"STATE\", \"ZIP_3\",\n",
    "    \"MI_PCT\", \"Product.Type\", \"CSCORE_C\", \"MI_TYPE\",\n",
    "    \"RELOCATION_FLG\"\n",
    ")\n",
    "\n",
    "PerformanceColumnNames = (\n",
    "    \"LOAN_ID\", \"Monthly.Rpt.Prd\", \"Servicer.Name\",\n",
    "    \"LAST_RT\", \"LAST_UPB\", \"Loan.Age\", \"Months.To.Legal.Mat\",\n",
    "    \"Adj.Month.To.Mat\", \"Maturity.Date\", \"MSA\",\n",
    "    \"Delq.Status\", \"MOD_FLAG\", \"Zero.Bal.Code\",\n",
    "    \"ZB_DTE\", \"LPI_DTE\", \"FCC_DTE\", \"DISP_DT\",\n",
    "    \"FCC_COST\", \"PP_COST\", \"AR_COST\", \"IE_COST\",\n",
    "    \"TAX_COST\", \"NS_PROCS\", \"CE_PROCS\", \"RMW_PROCS\",\n",
    "    \"O_PROCS\", \"NON_INT_UPB\", \"PRIN_FORG_UPB_FHFA\",\n",
    "    \"REPCH_FLAG\", \"PRIN_FORG_UPB_OTH\", \"TRANSFER_FLG\"\n",
    ")\n",
    "\n",
    "acquisition_df = pd.read_csv(\n",
    "    \"Acquisition_2010Q1.txt\",\n",
    "    names=AcquisitionColumnNames,\n",
    "    header=None,\n",
    "    sep=\"|\"\n",
    ")\n",
    "performance_df = pd.read_csv(\n",
    "    \"Performance_2010Q1.txt\",\n",
    "    names=PerformanceColumnNames,\n",
    "    header=None,\n",
    "    sep=\"|\"\n",
    ")\n",
    "DS = set(performance_df['Delq.Status'])\n",
    "mapper = {}\n",
    "for ds in DS:\n",
    "    try:\n",
    "        mapper[ds] = int(ds)\n",
    "    except:\n",
    "        mapper[ds] = -1\n",
    "performance_df['Delq.Status'] = performance_df['Delq.Status'].map(mapper)\n",
    "loans = performance_df.groupby(\"LOAN_ID\", sort=True)['Delq.Status'].max()\n",
    "ID_To_Delinq = {}\n",
    "for row in loans.iteritems():\n",
    "    loan_id, delinq = row\n",
    "    ID_To_Delinq[loan_id] = delinq\n",
    "def mapper(row):\n",
    "    return ID_To_Delinq.get(row[\"LOAN_ID\"], -1)\n",
    "acquisition_df['MAX_DELINQ'] = acquisition_df.apply(mapper, axis=1)\n",
    "DEL_NOTNAN = acquisition_df[\"MAX_DELINQ\"].notna()\n",
    "df = acquisition_df[DEL_NOTNAN]\n",
    "\n",
    "DEL_NOTNEG = df['MAX_DELINQ'] >= 0\n",
    "\n",
    "df = df[DEL_NOTNEG]\n",
    "OLTV = df['OLTV'].notna()\n",
    "df = df[OLTV]\n",
    "CS = df['CSCORE_B'].notna()\n",
    "df = df[CS]\n",
    "\n",
    "credit_score  = np.array(df['CSCORE_B'])\n",
    "loan_to_value = np.array(df['OLTV'])\n",
    "max_delinq    = np.array(df['MAX_DELINQ'])\n",
    "\n",
    "X = np.array([credit_score, loan_to_value]).transpose()\n",
    "y = np.array([max_delinq]).transpose()\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "Total = np.hstack([X, y])\n",
    "print(Total.shape)\n",
    "np.random.shuffle(Total)\n",
    "\n",
    "X = Total[:, :2]\n",
    "y = Total[:, 2:]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "prop = 0.8\n",
    "train_num = int(prop * len(Total))\n",
    "print(f\"Train Number: {train_num}\")\n",
    "\n",
    "X_train, X_test = X[:train_num], X[train_num:]\n",
    "y_train, y_test = y[:train_num], y[train_num:]\n",
    "\n",
    "print(f\"X_Train: {X_train.shape}\")\n",
    "print(f\"X_Test: {X_test.shape}\")\n",
    "print(\"==\"*10)\n",
    "print(f\"y_Train: {y_train.shape}\")\n",
    "print(f\"y_Test:  {y_test.shape}\")\n",
    "\n",
    "class_names = np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we implement the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score is 0.9067581379502586\n",
      "confusino matrix is [[58499   206    23 ...     0     0     0]\n",
      " [ 4066    54     8 ...     0     0     0]\n",
      " [  434     6     0 ...     0     0     0]\n",
      " ...\n",
      " [    1     0     0 ...     0     0     0]\n",
      " [    1     0     0 ...     0     0     0]\n",
      " [    1     0     0 ...     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "factory = ModelFactory()\n",
    "factory.register_model(\"dt\",DT_Fitter())\n",
    "data = DataSet(X_train,y_train, X_test, y_test)\n",
    "final_fitter = ObjFitter()\n",
    "final_fitter.fit(data,\"dt\",factory)\n",
    "print(f\"score is {final_fitter.get_score()}\")\n",
    "print(f\"confusion matrix is {final_fitter.get_confusion_matrix()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score is 0.9047914021123052\n",
      "confusion matrix is [[58368   300    35 ...     0     0     0]\n",
      " [ 4056    57     7 ...     0     0     0]\n",
      " [  428    10     0 ...     0     0     0]\n",
      " ...\n",
      " [    1     0     0 ...     0     0     0]\n",
      " [    1     0     0 ...     0     0     0]\n",
      " [    1     0     0 ...     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "factory.register_model(\"rf\",RF_Fitter())\n",
    "final_fitter.fit(data,\"rf\",factory)\n",
    "print(f\"score is {final_fitter.get_score()}\")\n",
    "print(f\"confusion matrix is {final_fitter.get_confusion_matrix()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score is 0.9102889707931985\n",
      "confusion matrix is [[58781     0     0 ...     0     0     0]\n",
      " [ 4140     0     0 ...     0     0     0]\n",
      " [  444     0     0 ...     0     0     0]\n",
      " ...\n",
      " [    1     0     0 ...     0     0     0]\n",
      " [    1     0     0 ...     0     0     0]\n",
      " [    1     0     0 ...     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "factory.register_model(\"svm\",SVM_Fitter())\n",
    "final_fitter.fit(data,\"svm\",factory,gamma='scale', decision_function_shape='ovo')\n",
    "print(f\"score is {final_fitter.get_score()}\")\n",
    "print(f\"confusion matrix is {final_fitter.get_confusion_matrix()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "4036/4036 [==============================] - 14s 3ms/step - loss: 1.0594 - sparse_categorical_accuracy: 0.8945 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "4036/4036 [==============================] - 6s 2ms/step - loss: 0.4376 - sparse_categorical_accuracy: 0.9101 - val_loss: 0.4239 - val_sparse_categorical_accuracy: 0.9103\n",
      "score is 0.9101443290710449\n",
      "confusion matrix is [[58781     0     0 ...     0     0     0]\n",
      " [ 4140     0     0 ...     0     0     0]\n",
      " [  444     0     0 ...     0     0     0]\n",
      " ...\n",
      " [    1     0     0 ...     0     0     0]\n",
      " [    1     0     0 ...     0     0     0]\n",
      " [    1     0     0 ...     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "factory.register_model(\"dnn\",DNN_Fitter())\n",
    "final_fitter.fit(data,\"dnn\",factory)\n",
    "print(f\"score is {final_fitter.get_score()}\")\n",
    "print(f\"confusion matrix is {final_fitter.get_confusion_matrix()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dt': 0.9067581379502586,\n",
       " 'rf': 0.9047914021123052,\n",
       " 'svm': 0.9102889707931985,\n",
       " 'dnn': 0.9101443}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_fitter.get_score_book()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
